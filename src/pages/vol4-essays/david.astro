---
import Layout from '~/layouts/PageLayout.astro';

const metadata = {
  title: 'Dialexicon',
  ignoreTitleTemplate: true,
};
---
<body style="background-color:#F9F6EE; background-position:cover; overflow-x:hidden; font-family:'Times New Roman', Times, serif">

<Layout metadata={metadata}>

    <div class="flex flex-row gap-4 absolute right-14 top-10 font-regular text-black">
        <a href="/" class="text-xl hover:italic" style="font-family:serif">Home </a>
        <a href="/about" class="text-xl hover:italic" style="font-family:serif">About </a>
        <a href="/journal" class="text-xl italic" style="font-family:serif"> Journal </a>
        <a href="/submit" class="text-xl hover:italic" style="font-family:serif"> Submit </a>
    </div>

  <div class="mt-14 ml-14" style="max-width:950px">
    <a href="/journal" class="text-blue-900 text-xl whitespace-pre hover:italic"> &#8592; Dialexicon Vol. 4 </a>
  </div>

  <div class="mt-16 ml-32 mr-32" style="">
  <div class="flex flex-col gap-3">
    <h1 class="text-blue-800 text-5xl">Blackening The Tech-Savvy Leviathan: Hobbes, Race, and Autonomous Security Technologies.</h1>
    <h1 class="text-blue-500 text-4xl italic"> David Xu </h1>
  </div>
  
  <div class="text-black mr-32 mt-8 text-xl">
    <span class="text-2xl text-blue-800">
      I. Introduction
    </span>
<span>
<div class="h-4"></div>
In 2016, the “Dallas sniper” Micah Xavier Johnson, who killed five cops at a Black Lives Matter protest, was killed via SWAT drone strike. This killing was the first use of a drone by police to kill a suspect on American soil. While Johnson’s actions were widely condemned, including by BLM activists, and I do not seek to redeem them, this paper will investigate new questions in sovereignty, race, and autonomous technologies sparked by the killing of a Black citizen by the American sovereign by use of drones. I begin by reading the Hobbesian social contract with Charles Mills’ The Racial Contract, then exploring how autonomous technologies have been interpreted by Hobbesian theorists for the American sovereign, and finally exploring how a racialized Hobbesian would approach the ethical question of said technologies.
<div class="h-4"></div>
<span class="text-2xl text-blue-800">
  II. Blackening Hobbes
  </span>
  <div class="h-4"></div>
Mills’ impact on philosophy was his reading of race as the central foundation in Western Philosophy. Inverting the color-ignorant assumption that footnoted racial concerns, Mills flips the presumption; “the racist ‘exception’ has really been the rule; what has been taken as the ‘rule’ the ideal norm, has really been the exception”. Instead of reading racism as an unfortunate byproduct, Mills recognizes, “a partitioned social ontology…divided between persons and racial sub persons”, as a precondition of contractarianism. For Hobbes, his social contract was used to escape the state of nature, an anarchist war, “of every man against every man”, where life was “nasty, brutish, and short”. In response, Hobbes proposes the cession of rights to “absolute sovereignty” as the sole arbiter of ethics and rights, resolving anarchist disorder. To demonstrate its racialization, Mills quotes Hobbes in, “his only real-life example”, of the state of nature as, “the savage people in many places of America”. This demonstrates the foundational white supremacy in Hobbes’ original theory, where absolute immorality and violence is only found in indigeneity. Beyond the violent emergence, Mills criticizes the Hobbesian racial contract as, “establishing a moral hierarchy…to secure and legitimate the privileging of those individuals designated as white/persons and the exploitation of those designated as nonwhite”, which can be seen within Hobbes’ ironic and racialized example of the state of nature as, “the very nonwhite people upon whose land his fellow Europeans were then encroaching”. However, the social contract’s racialized birth does not damn it to whiteness; Mills engages a recuperative project where, “contractarian liberalism can be radicalized, historicized, and racialized”, by moving from ideal theory’s ivory tower toward understanding, “modernity’s constitutive racialization”, to “redress its asymmetrical instantiations”. For Hobbes, this requires centering the very racism required to create his social contract to correct its racialized biases, ensuring its ethical and real-world robustness.
<div class="h-4"></div>
<span class="text-2xl text-blue-800">
    III. Blackening Autonomous Technologies
  </span>
<div class="h-4"></div>
For Hobbesians, the use of autonomous technologies e.g. autonomous weapons systems (AWS), drones, and predictive algorithms, by the military and police, resolves various tensions found within Hobbes’ social contract. Creating the sovereign eliminates anarchy to ensure the commonwealth’s stability, and autonomous technologies assist this mission in two ways. However, this paper will demonstrate how a failure to center race in autonomous deployment will lead to its failure as well. 
<div class="h-4"></div>
First, AWSs resolve a paradox unnoticed in peace. The Hobbesian contract relies on a, “mutual Relation between Protection and Obedience”, where the sovereign guarantees the subject’s protection in exchange for obedience. However, during wartime, “every man is bound … to protect in Warre, the authority by which he is himself protected in time of peace”. Thus, the contractual exchange erodes during wartime when the subject’s protection is not insured because of their military duty to the sovereign’s protection. To resolve the risk to the subject’s protection, autonomous weapons can, “feasibly replace combatants, thereby eliminating the need for human deployments…reduce the risk to American lives without diminishing U.S. combat capabilities”. However, the assumption that protection in exchange for obedience is sutured by whiteness. In the name of preserving peace, Hobbes further writes, “that a Subject may be put to death, by the command of the Soveraign Power”, because of the sovereign’s right to punishment. Although a citizen during peacetime enjoys protection, their citizen status is in jeopardy because of the porous border between civil and martial law, where the rights of citizens are not recognized when they are deemed an enemy of the state, either via war or criminal status. 
<div class="h-4"></div>
The deployment of AWSs in accordance with Hobbes’ social contract is complicated by the systematically-biased American judicial system, where Black people are, ”incarcerated in state prisons at nearly five times the rate of white Americans”. The precarious citizen status of racial minorities demonstrates Mills’ point that existing power structures are hierarchized via the racial contract and codified in legal structures. For autonomous weapons, the deployment of the piloted drone against a Black citizen further blurs the line between civil and martial law as the American police force militarizes. Along that telos, American police departments such as San Francisco and Boston have been adopting military, robotic weaponry. Although not yet autonomous, the shift from remotely piloted, to semi-autonomous, to fully autonomous is on the horizon for military/police technologies. This is important for racialized populations as the calculus for autonomous weapon technologies will be constantly deciding, “who is a threat…who is suspicious…who is an enemy”. Thus, the threat constructions of the black population by the American police in the present is embedded in the future as the, “production of suspects/targets/threats clearly parallels how in US cities Black youth congregating on street corners has long been read as the ‘signature’ or ‘personality’ of threat, thereby licensing police intervention.” In the context of warfare, as the American empire has historically engaged in racialized and violent military intervention in the Middle East, the present Orientalist threat construction is reproduced in an autonomous-warfare future as “Pakistani boys doing ‘jumping jacks’ are easily construed as a ‘terrorist training camp’” by drone program officials. Thus, the question of future autonomous technologies, when deployed by military/police forces, is inextricable from questions of present racialized threat construction, biases, and hierarchies. This complicates the autonomous solution to the Hobbesian problem; the precarious citizen status of racialized populations is entrenched in the racial contract, and military capabilities are reduced by ineffective, racially-biased autonomous weapons. 
<div class="h-4"></div>
Second, human administration – “biased, weak willed, exhaustible, unable to fully work” – is a problem for Hobbesians who require, “a political order that predicts, shapes, and reshape our collective behaviour in advance”, which “ensures that peace prevails, and every human action is under scrutiny of the political order”. One solution is predictive policing, where data analysis can predict, “where a crime may occur…who will be involved…for crime control and forecasting”. For Hobbesian, AWSs make, “perfect administrators and enforcers of law, unbiased and tireless…the perfection of the rule of law”,  a seemingly perfect solution to human error.
However, researchers found predictive policing recreates the racialized biases of police because the, “data reflects the practices, policies, biases…of a given department”. In a study of Microsoft, researchers found their algorithm to, “falsely flag black defendants as future criminals, wrongly labeling them [as greater crime risks] at almost twice the rate as white defendants”. while, “[w]hite defendants were mislabeled as low risk”. AWSs and predictive policing are two sides of the same coin where, “developing fully autonomous weapons…based on data-inputs and pre-programmed algorithms…exacerbate [long-standing inherent biases] and lead to deadly consequences”. Thus, the abstract solution of deploying predictive policing and AWSs to infallibly enforce the law only leads to retrenched racial biases and exacerbates the original problem of human error in the racial contract. 
<div class="h-4"></div>
These failures to integrate autonomous technologies within a social contract reflect Mills’ critique, where the construction of a Hobbes sovereign entrenches existing racial hierarchies. However, just as Mills believes that centering race can redeem social contract theory, centering concerns about racial biases would effectively ensure ethical autonomous technologies where, “input data are valid and are analyzed properly to avoid discrimination”, creating an opportunity to, “build safer communities, rather than cracking down harder on areas that are already struggling”. This has been demonstrated with predictive policing where, “using the algorithm in context…that’s sensitive to issues of racial justice…fewer people would go to jail, and the rate of racially-disparate false positives would almost disappear”. This move from an idealized view of autonomous weaponry/policing that recreates the legacy of racial bias towards centering how race materially affects the data that informs autonomous analytics is reflective of Mills’ reading of the, ”ideal of the social contract and the reality of the Racial Contract”.
<div class="h-4"></div>
<span class="text-2xl text-blue-800">
    IV. Conclusion
  </span>
  <div class="h-4"></div>
In this paper, I have located the Hobbesian social contract in Mills’ racial contract, investigated color-evasive Hobbesian approaches to autonomous technologies, their mistakes by ignoring how race would lead to the failure of those methods, and finally how Mills’ technique of centering race would be able to redeem historically racist theories and technologies. These autonomous technologies are neither good nor bad in a vacuum but can only be ethical and effective with a racialized lens, as “naming this reality brings it into the necessary theoretical focus for these issues to be addressed”.
<div class="h-4"></div>
<div class="text-black mr-32 text-xl mb-10">
  <span class="text-2xl text-blue-800"> 
    VII. Bibliography
  </span>
  <div class="h-4"></div>
  American Civil Liberties Union. “Race and Criminal Justice”. https://www.aclu.org/issues/racial-justice/race-and-criminal-justice
  <div class="h-4"></div>
  Bargu, B (2014) Sovereignty as erasure: Rethinking enforced disappearances. Qui Parle: Critical Humanities and Social Sciences 23(1): 35–75.
  <div class="h-4"></div>
  Choudhary, Priyanka. (2023). “Public Policy and Prospects of Pharmaceutical MSMEs: A Study with Special Reference to Dehradun, Uttarakhand.” XIX. 236-247.
<div class="h-4"></div>
  Mason, Ari. “Black Lives Matter Activists, Civil Rights Leaders Condemn Dallas Ambush”. NBC New York, 2016. 
  http://www.nbcnewyork.com/news/national-international/Dallas-Police-Shooting-Sniper-Black-Lives-Matter-NAACP-385997131.html
  Mills, Charles W. The Racial Contract. Cornell University Press, 1997. http://www.jstor.org/stable/10.7591/j.ctt5hh1wj
  <div class="h-4"></div>
  Har, Janie and Lauer, Claudia. “Police can now legally use killer robots and they’ve already deployed them a few times”, Fortune, December 5, 2022. https://fortune.com/2022/12/05/how-much-are-police-using-killer-robots-san-francisco/
  <div class="h-4"></div>
  Hobbes, Thomas. The Leviathan. Penguin Books, 1651.
  <div class="h-4"></div>
  Isaac, William And Dixoi, Andi. "Why big-data analysis of police activity is inherently biased." Phys.org, 10 May 2017, https://phys.org/news/2017-05-big-data-analysis-police-inherently-biased.html
  <div class="h-4"></div>
  MacIntosh, Duncan. “Autonomous Weapons and the Nature of Law and Morality: How Rule-of-Law-Values Require Automation of the Rule of Law”. Temple International and Comparative Law Journal, 2016. https://sites.temple.edu/ticlj/files/2017/02/30.1.MacIntosh-TICLJ.pdf
  <div class="h-4"></div>
  Mae Pedron, Stephanie and de Arimateia da Cruz, Jose. "The Future of Wars: Artificial Intelligence (AI) and Lethal Autonomous Weapon Systems (LAWS)." International Journal of Security Studies, 2(1). 2020. https://digitalcommons.northgeorgia.edu/cgi/viewcontent.cgi?article=1020&context=ijoss.
  <div class="h-4"></div>
  Marwah, Inder S., 'Charles W. Mills, The Racial Contract', in Jacob T. Levy (ed.), The Oxford Handbook of Classics in Contemporary Political Theory (online edn, Oxford Academic, 10 Dec. 2015), https://doi.org/10.1093/oxfordhb/9780198717133.013.62.
  <div class="h-4"></div>
  O'Donnell, Renata. "Challenging Racist Predictive Policing Algorithms Under the Equal Protection Clause." New York University Law Review, Volume 94, June 2019, https://www.nyulawreview.org/wp-content/uploads/2019/06/NYULawReview-94-3-ODonnell.pdf.
  <div class="h-4"></div>
  Ramsay-Jones, Hayley. “Racism and Fully Autonomous Weapons.” Campaign to Stop Killer Robots, October 17, 2019. https://www.ohchr.org/sites/default/files/Documents/Issues/Racism/SR/Call/campaigntostopkillerrobots.pdf
  <div class="h-4"></div>
  Richardson, Rashida, M. Schultz, Jason, and Crawford, Kate. “Dirty Data, Bad Predictions: How Civil Rights Violations Impact Police Data, Predictive Policing Systems, and Justice.” New York University Law Review, May 2019, https://www.nyulawreview.org/wp-content/uploads/2019/04/NYULawReview-94-Richardson-Schultz-Crawford.pdf
  <div class="h-4"></div>
  Schwartzapfel, Beth. "Can Racist Algorithms Be Fixed?" The Marshall Project, July 1, 20219. https://www.themarshallproject.org/2019/07/01/can-racist-algorithms-be-fixed
  <div class="h-4"></div>
  Wall, Tyler (School of Justice Studies, Eastern Kentucky University). “Ordinary Emergency: Drones, Police, and Geographies of Legal Terror”, Antipode Vol. 48, No. 4, 2016, pg.1124-1129
</Layout>